{"cells":[{"cell_type":"markdown","metadata":{"id":"g6c9mGHSmj1m"},"source":["```\n","# https://jair.org/index.php/jair/article/view/14329/26923\n","# This is formatted as code\n","```\n","\n","# QNLP Paper Code"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bFOHw850IaO_"},"outputs":[{"ename":"ValueError","evalue":"mount failed","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-1-d5df0069828e\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 2\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         )\n\u001b[0;32m--\u003e 287\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: mount failed"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":13681,"status":"ok","timestamp":1726535373991,"user":{"displayName":"Evren Yucekus-Kissane","userId":"14912278915292084096"},"user_tz":240},"id":"eC5bRMhqNmee","outputId":"c59d1734-9ba8-4f56-ae9f-fc3b91731065"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: discopy in /usr/local/lib/python3.10/dist-packages (1.1.7)\n","Requirement already satisfied: numpy\u003e=1.18.1 in /usr/local/lib/python3.10/dist-packages (from discopy) (1.26.4)\n","Requirement already satisfied: networkx\u003e=2.4 in /usr/local/lib/python3.10/dist-packages (from discopy) (3.3)\n","Requirement already satisfied: matplotlib\u003e=3.1.2 in /usr/local/lib/python3.10/dist-packages (from discopy) (3.7.1)\n","Requirement already satisfied: pillow\u003e=6.2.1 in /usr/local/lib/python3.10/dist-packages (from discopy) (9.4.0)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.1.2-\u003ediscopy) (1.3.0)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.1.2-\u003ediscopy) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.1.2-\u003ediscopy) (4.53.1)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.1.2-\u003ediscopy) (1.4.7)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.1.2-\u003ediscopy) (24.1)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.1.2-\u003ediscopy) (3.1.4)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.1.2-\u003ediscopy) (2.8.2)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.7-\u003ematplotlib\u003e=3.1.2-\u003ediscopy) (1.16.0)\n","Requirement already satisfied: qiskit in /usr/local/lib/python3.10/dist-packages (1.2.1)\n","Requirement already satisfied: rustworkx\u003e=0.15.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.15.1)\n","Requirement already satisfied: numpy\u003c3,\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.26.4)\n","Requirement already satisfied: scipy\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.1)\n","Requirement already satisfied: sympy\u003e=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.2)\n","Requirement already satisfied: dill\u003e=0.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.3.8)\n","Requirement already satisfied: python-dateutil\u003e=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (2.8.2)\n","Requirement already satisfied: stevedore\u003e=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (5.3.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit) (4.12.2)\n","Requirement already satisfied: symengine\u003e=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.11.0)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.8.0-\u003eqiskit) (1.16.0)\n","Requirement already satisfied: pbr\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore\u003e=3.0.0-\u003eqiskit) (6.1.0)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy\u003e=1.3-\u003eqiskit) (1.3.0)\n","Requirement already satisfied: pytket in /usr/local/lib/python3.10/dist-packages (1.32.0)\n","Requirement already satisfied: sympy\u003e=1.12.1 in /usr/local/lib/python3.10/dist-packages (from pytket) (1.13.2)\n","Requirement already satisfied: numpy\u003e=1.26.4 in /usr/local/lib/python3.10/dist-packages (from pytket) (1.26.4)\n","Requirement already satisfied: lark\u003e=1.1.9 in /usr/local/lib/python3.10/dist-packages (from pytket) (1.2.2)\n","Requirement already satisfied: scipy\u003e=1.13.1 in /usr/local/lib/python3.10/dist-packages (from pytket) (1.13.1)\n","Requirement already satisfied: networkx\u003e=2.8.8 in /usr/local/lib/python3.10/dist-packages (from pytket) (3.3)\n","Requirement already satisfied: graphviz\u003e=0.20.3 in /usr/local/lib/python3.10/dist-packages (from pytket) (0.20.3)\n","Requirement already satisfied: jinja2\u003e=3.1.4 in /usr/local/lib/python3.10/dist-packages (from pytket) (3.1.4)\n","Requirement already satisfied: typing-extensions\u003e=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pytket) (4.12.2)\n","Requirement already satisfied: qwasm\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pytket) (1.0.1)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2\u003e=3.1.4-\u003epytket) (2.1.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from qwasm\u003e=1.0.1-\u003epytket) (71.0.4)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy\u003e=1.12.1-\u003epytket) (1.3.0)\n","Requirement already satisfied: pytket-qiskit in /usr/local/lib/python3.10/dist-packages (0.56.0)\n","Requirement already satisfied: pytket\u003e=1.30.0 in /usr/local/lib/python3.10/dist-packages (from pytket-qiskit) (1.32.0)\n","Requirement already satisfied: qiskit\u003e=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pytket-qiskit) (1.2.1)\n","Requirement already satisfied: qiskit-ibm-runtime\u003e=0.24.1 in /usr/local/lib/python3.10/dist-packages (from pytket-qiskit) (0.29.0)\n","Requirement already satisfied: qiskit-aer\u003e=0.14.2 in /usr/local/lib/python3.10/dist-packages (from pytket-qiskit) (0.15.1)\n","Requirement already satisfied: numpy\u003e=1.26.4 in /usr/local/lib/python3.10/dist-packages (from pytket-qiskit) (1.26.4)\n","Requirement already satisfied: sympy\u003e=1.12.1 in /usr/local/lib/python3.10/dist-packages (from pytket\u003e=1.30.0-\u003epytket-qiskit) (1.13.2)\n","Requirement already satisfied: lark\u003e=1.1.9 in /usr/local/lib/python3.10/dist-packages (from pytket\u003e=1.30.0-\u003epytket-qiskit) (1.2.2)\n","Requirement already satisfied: scipy\u003e=1.13.1 in /usr/local/lib/python3.10/dist-packages (from pytket\u003e=1.30.0-\u003epytket-qiskit) (1.13.1)\n","Requirement already satisfied: networkx\u003e=2.8.8 in /usr/local/lib/python3.10/dist-packages (from pytket\u003e=1.30.0-\u003epytket-qiskit) (3.3)\n","Requirement already satisfied: graphviz\u003e=0.20.3 in /usr/local/lib/python3.10/dist-packages (from pytket\u003e=1.30.0-\u003epytket-qiskit) (0.20.3)\n","Requirement already satisfied: jinja2\u003e=3.1.4 in /usr/local/lib/python3.10/dist-packages (from pytket\u003e=1.30.0-\u003epytket-qiskit) (3.1.4)\n","Requirement already satisfied: typing-extensions\u003e=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pytket\u003e=1.30.0-\u003epytket-qiskit) (4.12.2)\n","Requirement already satisfied: qwasm\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pytket\u003e=1.30.0-\u003epytket-qiskit) (1.0.1)\n","Requirement already satisfied: rustworkx\u003e=0.15.0 in /usr/local/lib/python3.10/dist-packages (from qiskit\u003e=1.2.0-\u003epytket-qiskit) (0.15.1)\n","Requirement already satisfied: dill\u003e=0.3 in /usr/local/lib/python3.10/dist-packages (from qiskit\u003e=1.2.0-\u003epytket-qiskit) (0.3.8)\n","Requirement already satisfied: python-dateutil\u003e=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit\u003e=1.2.0-\u003epytket-qiskit) (2.8.2)\n","Requirement already satisfied: stevedore\u003e=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit\u003e=1.2.0-\u003epytket-qiskit) (5.3.0)\n","Requirement already satisfied: symengine\u003e=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit\u003e=1.2.0-\u003epytket-qiskit) (0.11.0)\n","Requirement already satisfied: psutil\u003e=5 in /usr/local/lib/python3.10/dist-packages (from qiskit-aer\u003e=0.14.2-\u003epytket-qiskit) (5.9.5)\n","Requirement already satisfied: requests\u003e=2.19 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibm-runtime\u003e=0.24.1-\u003epytket-qiskit) (2.32.3)\n","Requirement already satisfied: requests-ntlm\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibm-runtime\u003e=0.24.1-\u003epytket-qiskit) (1.3.0)\n","Requirement already satisfied: urllib3\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibm-runtime\u003e=0.24.1-\u003epytket-qiskit) (2.2.3)\n","Requirement already satisfied: websocket-client\u003e=1.5.1 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibm-runtime\u003e=0.24.1-\u003epytket-qiskit) (1.8.0)\n","Requirement already satisfied: ibm-platform-services\u003e=0.22.6 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibm-runtime\u003e=0.24.1-\u003epytket-qiskit) (0.57.0)\n","Requirement already satisfied: pydantic\u003e=2.5.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-ibm-runtime\u003e=0.24.1-\u003epytket-qiskit) (2.9.1)\n","Requirement already satisfied: ibm-cloud-sdk-core\u003c4.0.0,\u003e=3.20.6 in /usr/local/lib/python3.10/dist-packages (from ibm-platform-services\u003e=0.22.6-\u003eqiskit-ibm-runtime\u003e=0.24.1-\u003epytket-qiskit) (3.20.6)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2\u003e=3.1.4-\u003epytket\u003e=1.30.0-\u003epytket-qiskit) (2.1.5)\n","Requirement already satisfied: annotated-types\u003e=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic\u003e=2.5.0-\u003eqiskit-ibm-runtime\u003e=0.24.1-\u003epytket-qiskit) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic\u003e=2.5.0-\u003eqiskit-ibm-runtime\u003e=0.24.1-\u003epytket-qiskit) (2.23.3)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.8.0-\u003eqiskit\u003e=1.2.0-\u003epytket-qiskit) (1.16.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from qwasm\u003e=1.0.1-\u003epytket\u003e=1.30.0-\u003epytket-qiskit) (71.0.4)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19-\u003eqiskit-ibm-runtime\u003e=0.24.1-\u003epytket-qiskit) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19-\u003eqiskit-ibm-runtime\u003e=0.24.1-\u003epytket-qiskit) (3.8)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.19-\u003eqiskit-ibm-runtime\u003e=0.24.1-\u003epytket-qiskit) (2024.8.30)\n","Requirement already satisfied: cryptography\u003e=1.3 in /usr/local/lib/python3.10/dist-packages (from requests-ntlm\u003e=1.1.0-\u003eqiskit-ibm-runtime\u003e=0.24.1-\u003epytket-qiskit) (43.0.1)\n","Requirement already satisfied: pyspnego\u003e=0.4.0 in /usr/local/lib/python3.10/dist-packages (from requests-ntlm\u003e=1.1.0-\u003eqiskit-ibm-runtime\u003e=0.24.1-\u003epytket-qiskit) (0.11.1)\n","Requirement already satisfied: pbr\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore\u003e=3.0.0-\u003eqiskit\u003e=1.2.0-\u003epytket-qiskit) (6.1.0)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy\u003e=1.12.1-\u003epytket\u003e=1.30.0-\u003epytket-qiskit) (1.3.0)\n","Requirement already satisfied: cffi\u003e=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography\u003e=1.3-\u003erequests-ntlm\u003e=1.1.0-\u003eqiskit-ibm-runtime\u003e=0.24.1-\u003epytket-qiskit) (1.17.1)\n","Requirement already satisfied: PyJWT\u003c3.0.0,\u003e=2.8.0 in /usr/local/lib/python3.10/dist-packages (from ibm-cloud-sdk-core\u003c4.0.0,\u003e=3.20.6-\u003eibm-platform-services\u003e=0.22.6-\u003eqiskit-ibm-runtime\u003e=0.24.1-\u003epytket-qiskit) (2.9.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi\u003e=1.12-\u003ecryptography\u003e=1.3-\u003erequests-ntlm\u003e=1.1.0-\u003eqiskit-ibm-runtime\u003e=0.24.1-\u003epytket-qiskit) (2.22)\n"]}],"source":["from time import time\n","import pickle\n","import numpy as np\n","\n","!pip install discopy\n","!pip install qiskit\n","!pip install pytket\n","!pip install pytket-qiskit"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HAkZ8k1fULc7"},"outputs":[],"source":["from discopy.quantum.circuit import Qudit, Digit\n","#.channel Functor\n","#bit to Digit?\n","#from discopy.rigid import Ty\n","from discopy.rigid import Ob\n","from discopy.monoidal import Ty\n","#Digit to Ty?\n","from discopy.quantum.gates import Bits, Measure\n","#bit to Bits?\n","from discopy.quantum.zx import Diagram\n","#Up Box, Swap\n","from discopy.grammar.cfg import Id, Tree, Rule\n","#Up Box\n","from discopy.grammar.pregroup import Cup, Cap, Diagram, Swap, Functor, Word\n","from discopy.quantum.tk import Circuit as tk_Circuit\n","from discopy.quantum.tk import to_tk"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d6BDsJGWdn8r"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":2811,"status":"ok","timestamp":1726535376777,"user":{"displayName":"Evren Yucekus-Kissane","userId":"14912278915292084096"},"user_tz":240},"id":"Yizh4wI-Vk6o","outputId":"f6225480-bf27-4af8-8571-5443e9c1de5d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: qiskit in /usr/local/lib/python3.10/dist-packages (1.2.1)\n","Requirement already satisfied: qiskit_ionq in /usr/local/lib/python3.10/dist-packages (0.5.4)\n","Requirement already satisfied: pylatexenc in /usr/local/lib/python3.10/dist-packages (2.10)\n","Requirement already satisfied: rustworkx\u003e=0.15.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.15.1)\n","Requirement already satisfied: numpy\u003c3,\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.26.4)\n","Requirement already satisfied: scipy\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.1)\n","Requirement already satisfied: sympy\u003e=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.13.2)\n","Requirement already satisfied: dill\u003e=0.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.3.8)\n","Requirement already satisfied: python-dateutil\u003e=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (2.8.2)\n","Requirement already satisfied: stevedore\u003e=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (5.3.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit) (4.12.2)\n","Requirement already satisfied: symengine\u003e=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.11.0)\n","Requirement already satisfied: decorator\u003e=5.1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_ionq) (5.1.1)\n","Requirement already satisfied: requests\u003e=2.24.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_ionq) (2.32.3)\n","Requirement already satisfied: retry\u003e=0.9.0 in /usr/local/lib/python3.10/dist-packages (from qiskit_ionq) (0.9.2)\n","Requirement already satisfied: importlib-metadata\u003e=4.11.4 in /usr/local/lib/python3.10/dist-packages (from qiskit_ionq) (8.5.0)\n","Requirement already satisfied: python-dotenv\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from qiskit_ionq) (1.0.1)\n","Requirement already satisfied: zipp\u003e=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata\u003e=4.11.4-\u003eqiskit_ionq) (3.20.1)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.8.0-\u003eqiskit) (1.16.0)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.24.0-\u003eqiskit_ionq) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.24.0-\u003eqiskit_ionq) (3.8)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.24.0-\u003eqiskit_ionq) (2.2.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests\u003e=2.24.0-\u003eqiskit_ionq) (2024.8.30)\n","Requirement already satisfied: py\u003c2.0.0,\u003e=1.4.26 in /usr/local/lib/python3.10/dist-packages (from retry\u003e=0.9.0-\u003eqiskit_ionq) (1.11.0)\n","Requirement already satisfied: pbr\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore\u003e=3.0.0-\u003eqiskit) (6.1.0)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy\u003e=1.3-\u003eqiskit) (1.3.0)\n"]}],"source":["from qiskit_ibm_runtime import Sampler, Estimator, QiskitRuntimeService, Session\n","# https://docs.quantum.ibm.com/migration-guides/qiskit-algorithms-module#vqd-example\n","\n","from pytket.extensions.qiskit import AerBackend, IBMQBackend, IBMQEmulatorBackend\n","from pytket import Circuit as tk_Circuit\n","!pip install qiskit qiskit_ionq pylatexenc\n","from qiskit_ionq import IonQProvider"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":176,"status":"error","timestamp":1726535650287,"user":{"displayName":"Evren Yucekus-Kissane","userId":"14912278915292084096"},"user_tz":240},"id":"1ZVXndpoyAI9","outputId":"935ec8f0-f688-45be-8be6-6fe9915c73e8"},"outputs":[{"ename":"NameError","evalue":"name 'n_ty' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-25-aac3b211f457\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 139\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0ms_ty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# Type for S (sentence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 139\u001b[0;31m \u001b[0mr0_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_ty\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mvphr_ty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0mr1_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtv_ty\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mn_ty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0mr2_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madj_ty\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mnphr_ty_ty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'n_ty' is not defined"]}],"source":["#-----------------------------\n","# atomic pregroup grammar types\n","#-----------------------------\n","s, n = Ob('S'), Ob('N')\n","\n","#----------------------------------------\n","# settings concerning the ansaetze\n","#----------------------------------------\n","q_s = 1        # number of qubits for sentence type s\n","q_n = 1        # number of qubits for noun type n\n","depth = 1      # number of IQP layers for non-single-qubit words\n","p_n = 3        # number of parameters for a single-qubit word (noun); valued in {1,2,3}.\n","\n","#----------------------------------------\n","# Parameters concerning the optimisation\n","#----------------------------------------\n","n_runs = 1      # number of runs over training procedure\n","niter  = 100    # number of iterations for any optimisation run of training.\n","\n","#----------------------------------------\n","# Parameters for quantum computation\n","#----------------------------------------\n","max_n_shots = 2 ** 13  # maximum shots possible\n","\n","#---------------------\n","# Fix the backend\n","#---------------------\n","#backend = AerBackend()  # this is a noise free quantum simulation that will be carried out on your computer\n","                        # and which does not rely on an IBMQ account.\n","\n","# Alternatively:\n","# ***************      !!! Note: Insert here your IBMQ account token !!!\n","#provider = IBMQ.enable_account(WAUL3EgxQmFvYSB52uDAMgHg1Du9HmtH)\n","\n","provider = IonQProvider(\"WAUL3EgxQmFvYSB52uDAMgHg1Du9HmtH\")\n","backend = provider.get_backend(\"ionq_qpu.harmony\")\n","#backend = IBMQEmulatorBackend(\u003cbackend_name\u003e, \u003ccredentials\u003e)\n","#or\n"," #backend = IBMQBackend(\u003cbackend_name\u003e, \u003ccredentials\u003e)\n","\n","#******************************************\n","# Data import\n","#******************************************\n","\n","# import train, dev and test datasets: the data entries are all strings of the form 'label sentence'\n","# with the label in {0,1} and with the sentence of the form \"word1_POStag1 word2_POStag2 ...\"\n","\n","with open('/content/drive/Shared drives/QML-198-2024/Teams/WINNERS/dataset/mc_train_data.txt') as f:\n","    training_data_raw = f.readlines()\n","\n","with open('/content/drive/Shared drives/QML-198-2024/Teams/WINNERS/dataset/mc_dev_data.txt') as f:\n","    dev_data_raw = f.readlines()\n","\n","with open('/content/drive/Shared drives/QML-198-2024/Teams/WINNERS/dataset/mc_test_data.txt') as f:\n","    testing_data_raw = f.readlines()\n","\n","#***************************************************************\n","# Turn the raw input data into data structures convenient below\n","#***************************************************************\n","\n","vocab = dict()          # dictionary to be filled with the vocabulary in the form { word : POStag }\n","data = dict()           # dictionary to be filled with all the data (train, dev and test subsets); entries of the\n","                        # form { sentence : label } with label encoding '1' as [1.0, 0.0] and '0' as [0.0, 1.0]\n","training_data = []      # list of sentences in the train dataset as strings \"word1 word2 ...\"\n","dev_data = []           # list of sentences in the dev dataset as strings \"word1 word2 ...\"\n","testing_data = []       # list of sentences in the test dataset as strings \"word1 word2 ...\"\n","\n","# Go through the train data\n","for sent in training_data_raw:\n","    words = sent[2:].split()\n","    sent_untagged = ''\n","    for word in words:\n","      word_untagged, tag = word.split('_')\n","      vocab[word_untagged] = tag\n","      sent_untagged += word_untagged + ' '\n","    sentence = sent_untagged[:-1]\n","    training_data.append(sentence)\n","    label = np.array([1.0, 0.0]) if sent[0] == '1' else np.array([0.0, 1.0])\n","    data[sentence] = label\n","\n","# Go through the dev data\n","for sent in dev_data_raw:\n","    words = sent[2:].split()\n","    sent_untagged = ''\n","    for word in words:\n","        word_untagged, tag = word.split('_')\n","        vocab[word_untagged] = tag\n","        sent_untagged += word_untagged + ' '\n","    sentence = sent_untagged[:-1]\n","    dev_data.append(sentence)\n","    label = np.array([1.0, 0.0]) if sent[0] == '1' else np.array([0.0, 1.0])\n","    data[sentence] = label\n","\n","# Go through the test data\n","for sent in testing_data_raw:\n","    words = sent[2:].split()\n","    sent_untagged = ''\n","    for word in words:\n","        word_untagged, tag = word.split('_')\n","        vocab[word_untagged] = tag\n","        sent_untagged += word_untagged + ' '\n","    sentence = sent_untagged[:-1]\n","    testing_data.append(sentence)\n","    label = np.array([1.0, 0.0]) if sent[0] == '1' else np.array([0.0, 1.0])\n","    data[sentence] = label\n","\n","#*****************************************************\n","# The sentences as diagrams via CFG production rules\n","#*****************************************************\n","\n","#----------------------------\n","# Further POS tags:\n","#----------------------------\n","nphr, adj, tv, iv, vphr, s = Ob('NP'), Ob('ADJ'), Ob('TV'), Ob('IV'), Ob('VP'), Ob('S')\n","\n","#----------------------------\n","# The vocabulary in DisCoPy\n","#----------------------------\n","vocab_dict_boxes = dict()\n","for word, tag in vocab.items():\n","    if tag == 'N':\n","        vocab_dict_boxes.update({word: Word(word, n)})\n","    if tag == 'TV':\n","        vocab_dict_boxes.update({word: Word(word, tv)})\n","    if tag == 'ADJ':\n","        vocab_dict_boxes.update({word: Word(word, adj)})\n","\n","#-------------------------------------\n","# The CFG production rules as boxes\n","#-------------------------------------\n","# nphr, adj, tv, iv, vphr, s = Ty('NP'), Ty('ADJ'), Ty('TV'), Ty('IV'), Ty('VP'), Ty('S')\n","n = Ty(n)   # Type for NP (noun phrase)\n","vphr_ty = Ty(vphr)   # Type for VP (verb phrase)\n","tv_ty = Ty(tv)       # Type for TV (transitive verb)\n","adj_ty = Ty(adj)     # Type for ADJ (adjective)\n","iv_ty = Ty(iv)       # Type for IV (indefinite article)\n","s_ty = Ty(s)         # Type for S (sentence)\n","\n","r0_tensor = n_ty @ vphr_ty\n","r1_tensor = tv_ty @ n_ty\n","r2_tensor = adj_ty @ nphr_ty_ty\n","\n","r0 = Rule(Ty('R0'), Ty(r0_tensor), str(s))\n","r1 = Rule(Ty('R1'), Ty(r1_tensor), str(vphr))\n","r2 = Rule(Ty('R2'), Ty(r2_tensor), str(n))\n","r3 = Rule(Ty('R3'), Ty(iv), str(vphr))\n","r4 = Rule(Ty('R4'), Ty(n), str(n))\n","\n","#---------------------------------------------\n","# The needed grammatical sentence structures\n","#---------------------------------------------\n","\n","N_TV_N_ty = Ty(nphr) @ Ty(tv)\n","N_TV_N_ty_2 = N_TV_N_ty @ Ty(r4)\n","N_TV_N_ty_3 = r4 @ r1\n","\n","grammar_dict = {\n","    'N_TV_N': N_TV_N_ty_2 \u003e\u003e (N_TV_N_ty_3 \u003e\u003e r0),\n","    'N_TV_ADJ_N': ((Id(n @ tv) @ r2) \u003e\u003e (r4 @ r1) \u003e\u003e r0),\n","    'ADJ_N_TV_N': ((Id(adj @ n @ tv) @ r4) \u003e\u003e (r2 @ r1) \u003e\u003e r0),\n","    'ADJ_N_TV_ADJ_N': ((Id(adj @ n @ tv) @ r2) \u003e\u003e (r2 @ r1) \u003e\u003e r0)\n","}\n","\n","#---------------------------------------------\n","# Create CFG diagrams for the sentences\n","#---------------------------------------------\n","sentences_dict = dict()\n","for sentstr in list(data.keys()):\n","     grammar_id = ''\n","     sentence = Id(Ty())\n","     for word in sentstr.split(' '):\n","         grammar_id += (vocab[word] + '_')\n","         sentence = sentence @ vocab_dict_boxes[word]\n","     grammar_id = grammar_id[:-1]\n","     sentence = sentence \u003e\u003e grammar_dict[grammar_id]\n","     sentences_dict.update({sentstr: [sentence, grammar_id]})\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PmKXn8IhTTDR"},"outputs":[],"source":["|#***************************************************************\n","# Translation to pregroup grammar\n","#***************************************************************\n","from discopy.grammar.pregroup import draw\n","\n","# From POS tags to Pregroup types:\n","ob_pg = {n: n, s: s, adj: n @ n.l, tv: n.r @ s @ n.l, vphr:  n.r @ s, nphr: n}\n","\n","# From CFG rules to Pregroup reductions:\n","ar_pg = {\n","    r0: Cup(n, n.r) @ Id(s),\n","    r1: Id(n.r @ s) @ Cup(n.l, n),\n","    r2: Id(n) @ Cup(n.l, n),\n","    r3: Id(n.r @ s),\n","    r4: Id(n)\n","}\n","\n","# The vocabulary as DisCoPy boxes with pregroup types\n","vocab_pg = [Word(vocab_dict_boxes[word].name, ob_pg[vocab_dict_boxes[word].cod]) for word in vocab.keys()]\n","\n","# The mapping of morphisms\n","ar_pg.update({vocab_dict_boxes[word]: Word(vocab_dict_boxes[word].name, ob_pg[vocab_dict_boxes[word].cod]) for word in vocab.keys()})\n","\n","# The functor that translates from CFG to pregroup\n","t2p = Functor(ob_pg, ar_pg)\n","\n","sentences_pg_dict = dict()\n","for sentstr in sentences_dict:\n","    sentences_pg_dict.update({sentstr: [t2p(sentences_dict[sentstr][0]), sentences_dict[sentstr][1]]})\n","\n","#******************************************************************************************************\n","# (Optional) For visualisation: the sentences as pregroup diagrams -- before 'bending nouns around'\n","#******************************************************************************************************\n","\n","for sentstr in sentences_pg_dict:\n","    sentences_pg_dict[sentstr][0].draw()\n","\n","#******************************************************\n","# Bending the nouns around\n","#******************************************************\n","sentences_pg_psr_dict = dict()\n","\n","for sentstr in sentences_pg_dict:\n","    grammar_id = sentences_pg_dict[sentstr][1]\n","    num_words = len(grammar_id.split('_'))\n","    words = sentences_pg_dict[sentstr][0][:num_words].boxes\n","    grammar = sentences_pg_dict[sentstr][0][num_words:]\n","    if grammar_id == 'N_TV_N':\n","        noun1 = Box(words[0].name, n.r, Ty())\n","        noun2 = Box(words[2].name, n.l, Ty())\n","        words_new = (Cap(n.r, n) @ Cap(n, n.l)) \u003e\u003e (noun1 @ Id(n) @ words[1] @ Id(n) @ noun2)\n","    if grammar_id == 'ADJ_N_TV_N':\n","        noun1 = Box(words[1].name, n.l, Ty())\n","        noun2 = Box(words[3].name, n.l, Ty())\n","        words_new = (Cap(n, n.l) @ Cap(n, n.l)) \u003e\u003e (words[0] @ Id(n) @ noun1 @ words[2] @ Id(n) @ noun2)\n","    if grammar_id == 'N_TV_ADJ_N':\n","        noun1 = Box(words[0].name, n.r, Ty())\n","        noun2 = Box(words[3].name, n.l, Ty())\n","        words_new = (Cap(n.r, n) @ Cap(n, n.l)) \u003e\u003e (noun1 @ Id(n) @ words[1] @ words[2] @ Id(n) @ noun2)\n","    if grammar_id == 'ADJ_N_TV_ADJ_N':\n","        noun1 = Box(words[1].name, n.l, Ty())\n","        noun2 = Box(words[4].name, n.l, Ty())\n","        words_new = (Cap(n, n.l) @ Cap(n, n.l)) \u003e\u003e (words[0] @ Id(n) @ noun1 @ words[2] @ words[3] @ Id(n) @ noun2)\n","    # add newly wired sentence to dictionary\n","    sentence = words_new \u003e\u003e grammar\n","    # Yank snakes and add to dictionary\n","    sentences_pg_psr_dict.update({sentstr: sentence.normal_form()})\n","\n","# Now for the vocab\n","vocab_psr = []\n","for word in vocab_pg:\n","    if word.cod == Ty('N'):\n","        vocab_psr.append(Box(word.name, n.r, Ty()))   # n.l case is dealt with in definition of quantum functor\n","    else:\n","        vocab_psr.append(word)\n","\n","#******************************************************************************************************\n","# (Optional) For visualisation: the sentences as pregroup diagrams -- after 'bending nouns around'\n","#******************************************************************************************************\n","for sentstr in sentences_pg_psr_dict:\n","    sentences_pg_psr_dict[sentstr].draw()\n","\n","#*****************************************************\n","# Translation to quantum circuits\n","#*****************************************************\n","from discopy.quantum import Ket, IQPansatz, Bra\n","from discopy.quantum.gates import sqrt, H, CZ, Rz, Rx, CX\n","from discopy.quantum.circuit import Id\n","from discopy import CircuitFunctor\n","from discopy.quantum.circuit import Circuit as DCP_Circuit\n","\n","ob = {s: q_s, n: q_n}                           # assignment of number of qubits to atomic grammatical types\n","ob_cqmap = {s: qubit ** q_s, n: qubit ** q_n}   # the form in which it is needed for discopy's cqmap module\n","\n","#-----------------------------------------\n","# parametrised part of ansaetze\n","#-----------------------------------------\n","\n","def single_qubit_iqp_ansatz(params):\n","    if len(params) == 1:\n","        return Rx(params[0])\n","    if len(params) == 2:\n","        return Rx(params[0]) \u003e\u003e Rz(params[1])\n","    if len(params) == 3:\n","        return IQPansatz(1, params)\n","\n","def ansatz_state(state, params):\n","    arity = sum(ob[Ty(factor.name)] for factor in state.cod)\n","    if arity == 1:\n","        return Ket(0) \u003e\u003e single_qubit_iqp_ansatz(params)\n","    else:\n","        return Ket(*tuple([0 for i in range(arity)])) \u003e\u003e IQPansatz(arity, params)\n","\n","def ansatz_effect(effect, params):\n","    arity = sum(ob[Ty(factor.name)] for factor in effect.dom)\n","    if arity == 1:\n","        return single_qubit_iqp_ansatz(params) \u003e\u003e Bra(0)\n","    else:\n","        return IQPansatz(arity, params) \u003e\u003e Bra(*tuple([0 for i in range(arity)]))\n","\n","def ansatz(box,params):\n","    dom_type = box.dom\n","    cod_type = box.cod\n","    if len(dom_type) == 0 and len(cod_type) != 0:\n","        return ansatz_state(box, params)\n","    if len(dom_type) != 0 and len(cod_type) == 0:\n","        return ansatz_effect(box, params)\n","\n","#----------------------------------------------------------\n","# Define parametrised functor to quantum circuits\n","#----------------------------------------------------------\n","def F(params):\n","    ar = dict()\n","    for i in range(len(vocab_psr)):\n","        pgbox = vocab_psr[i]\n","        qbox = ansatz(vocab_psr[i], params[i])\n","        ar.update({pgbox: qbox})\n","        if pgbox.cod == Ty():\n","            ar.update({Box(pgbox.name, n.l, Ty()): qbox})  # send the effect with n.l to same quantum effect\n","    return CircuitFunctor(ob_cqmap, ar)\n","\n","#*****************************************************\n","# Functions to deal with the parametrisation\n","#*****************************************************\n","\n","def paramshapes(vocab_psr):\n","    parshapes = []\n","    for box in vocab_psr:\n","        dom_type = box.dom\n","        cod_type = box.cod\n","        dom_arity = sum(ob[Ty(factor.name)] for factor in box.dom)\n","        cod_arity = sum(ob[Ty(factor.name)] for factor in box.cod)\n","        if dom_arity == 0 or cod_arity == 0:  # states and effects\n","            arity = max(dom_arity, cod_arity)\n","            assert arity != 0\n","            if arity == 1:\n","                parshapes.append((p_n,))\n","            if arity != 1:\n","                parshapes.append((depth, arity-1))\n","    return parshapes\n","\n","def randparams(par_shapes):\n","    params = np.array([])\n","    for i in range(len(par_shapes)):\n","        params = np.concatenate((params, np.ravel(np.random.rand(*par_shapes[i]))))\n","    return params\n","\n","def reshape_params(unshaped_pars, par_shapes):\n","    pars_reshaped = [[] for ii in range(len(par_shapes))]\n","    shift = 0\n","    for ss, s in enumerate(par_shapes):\n","        idx0 = 0 + shift\n","        if len(s) == 1:\n","            idx1 = s[0] + shift\n","        elif len(s) == 2:\n","            idx1 = s[0] * s[1] + shift\n","        pars_reshaped[ss] = np.reshape(unshaped_pars[idx0:idx1], s)\n","        if len(s) == 1:\n","            shift += s[0]\n","        elif len(s) == 2:\n","            shift += s[0] * s[1]\n","    return pars_reshaped\n","\n","#****************************************\n","# Parameters of the current model\n","#****************************************\n","\n","par_shapes = paramshapes(vocab_psr)\n","rand_unshaped_pars = randparams(par_shapes)\n","rand_shaped_pars = reshape_params(rand_unshaped_pars, par_shapes)\n","\n","print('Number of parameters:    ', len(rand_unshaped_pars))\n","\n","#**************************************************************\n","# (Optional) Quantum circuit diagrams for the sentences\n","#**************************************************************\n","\n","func = F(rand_shaped_pars)\n","\n","for sentstr in sentences_pg_psr_dict:\n","    func(sentences_pg_psr_dict[sentstr]).draw(draw_box_labels=True, figsize=(5, 5))\n","\n","#********************************************************************************************\n","# Encode data such that the circuits (for one call of cost function etc.) can be sent as one\n","# job to quantum hardware.\n","#********************************************************************************************\n","\n","train_labels = []\n","train_circuits_pg_psr = []\n","for sentstr in training_data:\n","    train_circuits_pg_psr.append(sentences_pg_psr_dict[sentstr])\n","    train_labels.append(np.array(data[sentstr]))\n","train_labels = np.array(train_labels)\n","\n","dev_labels = []\n","dev_circuits_pg_psr = []\n","for sentstr in dev_data:\n","    dev_circuits_pg_psr.append(sentences_pg_psr_dict[sentstr])\n","    dev_labels.append(np.array(data[sentstr]))\n","dev_labels = np.array(dev_labels)\n","\n","test_labels = []\n","test_circuits_pg_psr = []\n","for sentstr in testing_data:\n","    test_circuits_pg_psr.append(sentences_pg_psr_dict[sentstr])\n","    test_labels.append(np.array(data[sentstr]))\n","test_labels = np.array(test_labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4uwYvZ1BmoMl"},"outputs":[],"source":["#**********************************************************************************\n","# Split cost and error functions for time efficiency\n","#**********************************************************************************\n","\n","def get_probs(unshaped_params):\n","    func = F(reshape_params(unshaped_params, par_shapes))\n","    train_circuits = [(func(circ) \u003e\u003e Measure()) for circ in train_circuits_pg_psr]\n","    results = DCP_Circuit.eval(*train_circuits, backend=backend, n_shots=max_n_shots, compilation=backend.default_compilation_pass(2))\n","    results_tweaked = [np.abs(np.array(res.array) - 1e-9) for res in results]\n","    pred_labels_distrs = [res / np.sum(res) for res in results_tweaked]\n","    return pred_labels_distrs\n","\n","def get_cost(pred_labels_distrs):\n","    cross_entropies = np.array([np.sum(train_labels[s] * np.log2(pred_labels_distrs[s])) for s in range(len(train_labels))])\n","    return -1 / len(training_data) * np.sum(cross_entropies)\n","\n","def get_train_error(pred_labels_distrs):\n","    error = 0.0\n","    assert len(pred_labels_distrs[0]) == 2  # rounding only makes sense if labels are binary tuples\n","    pred_labels = [np.round(res) for res in pred_labels_distrs]\n","    for i in range(len(pred_labels)):\n","        if np.sum(pred_labels[i]) != 1.0:  # when equal weights or no counts gives label [1,1] (due to - 1e-9)\n","            error += 1\n","        else:\n","            error += np.abs(train_labels[i][0] - pred_labels[i][0]) # above ensures precited label as [0,1] or [1,0]\n","    return round(error * 100 / len(training_data), 1)\n","\n","def get_dev_error(unshaped_params):\n","    func = F(reshape_params(unshaped_params, par_shapes))\n","    dev_circuits = [(func(circ) \u003e\u003e Measure()) for circ in dev_circuits_pg_psr]\n","    results = DCP_Circuit.eval(*dev_circuits, backend=backend, n_shots=max_n_shots, compilation=backend.default_compilation_pass(2))\n","    results_tweaked = [np.abs(np.array(res.array) - 1e-9) for res in results]\n","    assert len(results_tweaked[0]) == 2\n","    pred_labels = [np.round(res / np.sum(res)) for res in results_tweaked]\n","    error = 0.0\n","    for i in range(len(pred_labels)):\n","        if np.sum(pred_labels[i]) != 1.0:\n","            error += 1\n","        else:\n","            error += np.abs(dev_labels[i][0] - pred_labels[i][0])\n","    error = round(error * 100 / len(dev_data), 1)\n","    return error, pred_labels\n","\n","def get_test_error(unshaped_params):\n","    func = F(reshape_params(unshaped_params, par_shapes))\n","    test_circuits = [(func(circ) \u003e\u003e Measure()) for circ in test_circuits_pg_psr]\n","    results = DCP_Circuit.eval(*test_circuits, backend=backend, n_shots=max_n_shots, compilation=backend.default_compilation_pass(2))\n","    results_tweaked = [np.abs(np.array(res.array) - 1e-9) for res in results]\n","    assert len(results_tweaked[0]) == 2\n","    pred_labels = [np.round(res / np.sum(res)) for res in results_tweaked]\n","    error = 0.0\n","    for i in range(len(pred_labels)):\n","        if np.sum(pred_labels[i]) != 1.0:\n","            error += 1\n","        else:\n","            error += np.abs(test_labels[i][0] - pred_labels[i][0])\n","    error = round(error * 100 / len(testing_data), 1)\n","    return error, pred_labels\n","\n","#**********************************************************************************\n","# Minimization algorithm\n","#**********************************************************************************\n","\n","# This is building on the minimizeSPSA function from the noisyopt package (https://github.com/andim/noisyopt);\n","# here only adjusted for our purposes. As this is an example notebook for a final run of the experiment\n","# the dev set is not used here.\n","\n","def my_spsa(get_probs, get_cost, get_train_error, get_test_error, x0,\n","            bounds=None, niter=100, a=1.0, c=1.0, alpha=0.602, gamma=0.101,\n","            print_iter=False, correct_func_value=True,\n","            filename='spsa_output', iters_selected=[]):\n","    A = 0.01 * niter\n","    N = len(x0)\n","    if bounds is None:\n","        project = lambda x: x\n","    else:\n","        bounds = np.asarray(bounds)\n","        project = lambda x: np.clip(x, bounds[:, 0], bounds[:, 1])\n","    param_history = []\n","    func_history = []\n","    error_history = []\n","    pred_label_history = []\n","    pred_labels_test_error = dict()\n","    test_error_list = []\n","    x = x0\n","\n","    # Loop over iterations\n","    for k in range(niter):\n","        if print_iter:\n","            print('-------------', '\\n', 'iteration: ', k, sep='')\n","        start = time()\n","\n","        # determine stepping parameters\n","        ak = a/(k+1.0+A)**alpha\n","        ck = c/(k+1.0)**gamma\n","        delta = np.random.choice([-1, 1], size=N)\n","\n","        # move in + direction from previous x\n","        xplus = project(x + ck*delta)\n","        if print_iter:\n","            print('Call for xplus')\n","        results_tweaked_plus = get_probs(xplus)\n","        funcplus = get_cost(results_tweaked_plus)\n","\n","        # move in - direction from previous x\n","        xminus = project(x - ck*delta)\n","        if print_iter:\n","            print('Call for xminus')\n","        results_tweaked_minus = get_probs(xminus)\n","        funcminus = get_cost(results_tweaked_minus)\n","\n","        # new step\n","        grad = (funcplus - funcminus) / (xplus-xminus)\n","        x = project(x - ak*grad)\n","        param_history.append(x)\n","\n","        # determine current func and error\n","        if correct_func_value or k == (niter - 1):  # In order to save time the cost at x is only evaluated for final step\n","            if print_iter:\n","                print('Call for current_func_value')\n","            results_tweaked = get_probs(x)\n","            current_func_value = get_cost(results_tweaked)\n","            error = get_train_error(results_tweaked)\n","            pred_label_history.append(results_tweaked)\n","        else:\n","            current_func_value = funcplus\n","            error = get_train_error(results_tweaked_plus)\n","            pred_label_history.append(results_tweaked_plus)\n","\n","        # calculate test error if a 'selected iteration'\n","        if k in iters_selected:\n","            print('Calculate test error for iteration:', k)\n","            res = get_test_error(x)\n","            test_error_list.append(res[0])\n","            pred_labels_test_error.update({k: res[1]})\n","\n","        func_history.append(current_func_value)\n","        error_history.append(error)\n","\n","        # save to file\n","        dump_data = {\n","            'param_history': param_history,\n","            'func_history': func_history,\n","            'error_history': error_history,\n","            'predlabel_history': pred_label_history,\n","            'iters_selected': iters_selected,\n","            'test_error_list': test_error_list,\n","            'pred_labels_test_error': pred_labels_test_error\n","        }\n","        with open(filename+'.pickle', 'wb') as file_handle:\n","            pickle.dump(dump_data, file_handle)\n","\n","        if print_iter:\n","            print('Time taken for this iteration: ', time() - start)\n","    return param_history, func_history, error_history, test_error_list\n","\n","#************************************\n","# Quantum run: training and error calculation\n","#************************************\n","\n","bounds = [[0.0, 1.0] for ii in range(len(rand_unshaped_pars))]\n","c_fix = 0.1\n","a_est = 0.015\n","\n","param_histories = []\n","cost_histories = np.zeros((n_runs, niter))\n","error_train_histories = np.zeros((n_runs, niter))\n","\n","# For test error calculation (for reasons of time cost not for all iterations)\n","iters_selected = [(i+1)*10-1 for i in range(int(niter/10))]\n","iters_selected.insert(0, 0)\n","error_test_histories = np.zeros((n_runs, len(iters_selected)))\n","\n","for i in range(n_runs):\n","    print('---------------------------------')\n","    print('Start run ', i+1)\n","    rand_unshaped_pars = randparams(par_shapes)\n","    start = time()\n","    res = my_spsa(get_probs, get_cost, get_train_error, get_test_error, rand_unshaped_pars,\n","                  bounds=bounds, niter=niter, a=a_est, c=c_fix,\n","                  print_iter=True, correct_func_value=False, filename=('MC_task_SPSAOutput_Run' + str(i)),\n","                  iters_selected=iters_selected)\n","    param_histories.append(res[0])\n","    cost_histories[i, :] = res[1]\n","    error_train_histories[i, :] = res[2]\n","    error_test_histories[i, :] = res[3]\n","    print('run', i+1, 'done')\n","    print('Time taken: ', time() - start)\n","\n","#****************************************************\n","# Averaging\n","#****************************************************\n","\n","# In case N_runs \u003e 1, one may want to calculate cost and errors averaged over several runs...\n","\n","# In this example notebook however not done, hence:\n","cost_history = cost_histories[0, :]\n","error_train_history = error_train_histories[0, :]\n","error_test_history = error_test_histories[0, :]\n","\n","#****************************************************\n","# Summary plot\n","#****************************************************\n","from matplotlib import pyplot as plt\n","\n","fig, ax1 = plt.subplots(figsize=(13, 8))\n","\n","ax1.plot(range(len(cost_history)), cost_history, '-k', markersize=4, label='cost')\n","ax1.set_ylabel(r\"Cost\", fontsize='x-large')\n","ax1.set_xlabel(r\"SPSA~iterations\", fontsize='x-large')\n","ax1.legend(loc='upper center', fontsize='x-large')\n","\n","ax2 = ax1.twinx()\n","ax2.set_ylabel(r\"Error in \\%\", fontsize='x-large')\n","ax2.plot(range(len(error_train_history)), error_train_history, '-g', markersize=4, label='training error')\n","ax2.plot(iters_selected, error_test_history, 'xb', markersize=7, label='testing error')\n","ax2.legend(loc='upper right', fontsize='x-large')\n","\n","plt.title('MC task, quantum run -- results', fontsize='x-large')\n","plt.savefig('MC_task_Results.png', dpi=300, facecolor='white')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ycBslSe-IPfc"},"outputs":[],"source":[]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}